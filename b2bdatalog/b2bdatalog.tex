%%
%% This is file `sample-manuscript.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `manuscript')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-manuscript.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass command.
%%%% Small single column format, used for CIE, CSUR, DTRAP, JACM, JDIQ, JEA, JERIC, JETC, PACMCGIT, TAAS, TACCESS, TACO, TALG, TALLIP (formerly TALIP), TCPS, TDSCI, TEAC, TECS, TELO, THRI, TIIS, TIOT, TISSEC, TIST, TKDD, TMIS, TOCE, TOCHI, TOCL, TOCS, TOCT, TODAES, TODS, TOIS, TOIT, TOMACS, TOMM (formerly TOMCCAP), TOMPECS, TOMS, TOPC, TOPLAS, TOPS, TOS, TOSEM, TOSN, TQC, TRETS, TSAS, TSC, TSLP, TWEB.
% \documentclass[acmsmall]{acmart}

%%%% Large single column format, used for IMWUT, JOCCH, PACMPL, POMACS, TAP, PACMHCI
% \documentclass[acmlarge,screen]{acmart}

%%%% Large double column format, used for TOG
% \documentclass[acmtog, authorversion]{acmart}

%%%% Generic manuscript mode, required for submission
%%%% and peer review
\documentclass[manuscript,screen,review]{acmart}
%% Fonts used in the template cannot be substituted; margin 
%% adjustments are not allowed.
%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
\providecommand\BibTeX{{%
\normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmcopyright}
\copyrightyear{2018}
\acmYear{2018}
\acmDOI{XXXXXXX.XXXXXXX}

%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[Conference acronym 'XX]{Make sure to enter the correct
	conference title from your rights confirmation emai}{June 03--05,
	2018}{Woodstock, NY}
%
%  Uncomment \acmBooktitle if th title of the proceedings is different
%  from ``Proceedings of ...''!
%
\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
	June 03--05, 2018, Woodstock, NY}
\acmPrice{15.00}
\acmISBN{978-1-4503-XXXX-X/18/06}


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}
\theoremstyle{definition}
\newtheorem{exmp}{Example}[section]
\usepackage[ruled, vlined, linesnumbered]{algorithm2e}
\SetKw{True}{true}
\SetKw{False}{false}
\SetKwData{typeInt}{Int}
\SetKwData{typeRat}{Rat}
\SetKwData{Defined}{Defined}
\SetKwFunction{parseStatement}{parseStatement}

%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{A Back-to-basics empirical study of Datalog}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Bruno Rucy Carneiro Alves de Lima}
\authornote{Both authors contributed equally to this research.}
\email{bruno.rucy.carneiro.alves.de.lima@ut.ee}
\orcid{1234-5678-9012}

\author{G.K.M. Tobin}
\authornotemark[1]
\email{webmaster@marysville-ohio.com}
\affiliation{%
	\institution{Institute for Clarity in Documentation}
	\streetaddress{P.O. Box 1212}
	\city{Dublin}
	\state{Ohio}
	\country{USA}
	\postcode{43017-6221}
}

\author{Lars Th{\o}rv{\"a}ld}
\affiliation{%
\institution{The Th{\o}rv{\"a}ld Group}
\streetaddress{1 Th{\o}rv{\"a}ld Circle}
\city{Hekla}
\country{Iceland}}
\email{larst@affiliation.org}

\author{Valerie B\'eranger}
\affiliation{%
	\institution{Inria Paris-Rocquencourt}
	\city{Rocquencourt}
	\country{France}
}

\author{Aparna Patel}
\affiliation{%
	\institution{Rajiv Gandhi University}
	\streetaddress{Rono-Hills}
	\city{Doimukh}
	\state{Arunachal Pradesh}
	\country{India}}

\author{Huifen Chan}
\affiliation{%
	\institution{Tsinghua University}
	\streetaddress{30 Shuangqing Rd}
	\city{Haidian Qu}
	\state{Beijing Shi}
	\country{China}}

\author{Charles Palmer}
\affiliation{%
	\institution{Palmer Research Laboratories}
	\streetaddress{8600 Datapoint Drive}
	\city{San Antonio}
	\state{Texas}
	\country{USA}
	\postcode{78229}}
\email{cpalmer@prl.com}

\author{John Smith}
\affiliation{%
\institution{The Th{\o}rv{\"a}ld Group}
\streetaddress{1 Th{\o}rv{\"a}ld Circle}
\city{Hekla}
\country{Iceland}}
\email{jsmith@affiliation.org}

\author{Julius P. Kumquat}
\affiliation{%
	\institution{The Kumquat Consortium}
	\city{New York}
	\country{USA}}
\email{jpkumquat@consortium.net}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Trovato and Tobin, et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
	A clear and well-documented \LaTeX\ document is presented as an
	article formatted for publication by ACM in a conference proceedings
	or journal publication. Based on the ``acmart'' document class, this
	article presents and explains many of the common variations, as well
	as many of the formatting elements an author may use in the
	preparation of the documentation of their work.
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
	<ccs2012>
	<concept>
	<concept_id>10010520.10010553.10010562</concept_id>
	<concept_desc>Computer systems organization~Embedded systems</concept_desc>
	<concept_significance>500</concept_significance>
	</concept>
	<concept>
	<concept_id>10010520.10010575.10010755</concept_id>
	<concept_desc>Computer systems organization~Redundancy</concept_desc>
	<concept_significance>300</concept_significance>
	</concept>
	<concept>
	<concept_id>10010520.10010553.10010554</concept_id>
	<concept_desc>Computer systems organization~Robotics</concept_desc>
	<concept_significance>100</concept_significance>
	</concept>
	<concept>
	<concept_id>10003033.10003083.10003095</concept_id>
	<concept_desc>Networks~Network reliability</concept_desc>
	<concept_significance>100</concept_significance>
	</concept>
	</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Computer systems organization~Embedded systems}
\ccsdesc[300]{Computer systems organization~Redundancy}
\ccsdesc{Computer systems organization~Robotics}
\ccsdesc[100]{Networks~Network reliability}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{datasets, neural networks, gaze detection, text tagging}

%% A "teaser" image appears between the author and affiliation
%% information and the body of the document, and typically spans the
%% page.
\begin{teaserfigure}
	\includegraphics[width=\textwidth]{sampleteaser}
	\caption{Seattle Mariners at Spring Training, 2010.}
	\Description{Enjoying the baseball game from the third-base
		seats. Ichiro Suzuki preparing to bat.}
	\label{fig:teaser}
\end{teaserfigure}

\received{20 February 2007}
\received[revised]{12 March 2009}
\received[accepted]{5 June 2009}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}
\textbf{Motivation.} SQL has been the \textit{de facto} universal relational
database interface for querying and management since its inception,
with all other alternatives having had experienced disproportionately
little interest. The reasons for this are many, out of which only one
is relevant to this narrative; performance. Curiously, there doesn't seem to exist
a seminal article that investigates this event either from the
technological or antropological viewpoint.

The runner-ups of popularity were languages used for machine reasoning,
a subset of the Artificial Intelligence field that attempts to attain
intelligence through the usage of rules over knowledge. The canonical
language for reasoning over relational databases is datalog\cite{datalog}.
Similarly to SQL, it also is declarative, however, its main semantics' difference
is in the support for recursion while still ensuring termination irrespective
of the program being run.

A notable issue with respect to real-world adoption of datalog is in
tractability. The combined complexity of evaluating a program is
$\text{EXPTIME}$\cite{datalog}, while SQL queries are $\text{AC}^0$. It was
not until recently\cite{rdfox, others?} that scalable implementations were
developed.

Digital analytics has been one of the main drivers of the recent datalog renaissance,
with virtually all big-data oriented datalog implementations having had either been built
on top of the most mainstream industry oriented frameworks\cite{bigdatalog,cog,cog2} or with the
aid of the most high-profile technology companies\cite{logica,yedalog,vadalog}.

Another strong source of research interest has been from the knowledge graph community. A
knowledge graph \textit{KG} is a regular relational database \textit{I} that contains
\textit{ground truths}, and rules. The most important operation is called \textit{materialization},
the derivation of all truths that follow from the application of rules over the relational database,
with the most straightforward goal being to ensure queries to have the lowest latency.

\textbf{Problem.} Seeking ways to introduce tuple-generating dependencies to datalog
programs, with evaluation remaining tractable, has been one of the most active research
directions, with highly-influential papers establishing new families of datalog languages\cite{datalog_plus_minus}
and thoroughly exploring their complexity classes alongside further expansions\cite{sticky,warded,monadic}.

These advancements have been somewhat tested in practice, albeit with no full reference implementation having
been specified. The most comprehensive, and recent, is closed-source\cite{vadalog}. The
leading datalog engine in general, is also closed-source\cite{rdfox}, with no open-source
implementation having had attained any level of popularity, despite the relative simplicity
of the language itself.

The two most popular datalog-related projects are DataScript\cite{datascript} and
Open Policy Agent\cite{opa}, with the former being a top-down engine whose novelty lies in
covering much functionality from a proprietary project, Datomic\cite{datomic}, while being
implemented on top of a simple in-memory B-Tree. The latter is also a top-down evaluator,
with severely limited usage of recursion. Neither of these projects have an intrinsic didactic
nor scientific value.

The lack of a canonical open-source implementation of datalog makes attempts at making
empirical statements about performance-impacting theoretical developments brittle and
difficult, since there is no point of reference to compare and validate, and comparisons
against commercial implementations are not reliable, since optimizations might be trade secrets.

A notorious exploration that highlights this issue is the COST, Configuration That Outperforms
a Single Thread, article\cite{COST}, in which the author posits that multiple published
graph-processing engines are likely never able to outperform simple single-threaded implementations.
Some high-profile datalog implementations were built upon systems mentioned on that article.
Later on, the author made multiple pieces of informal writing in which the most performant datalog
engines were investigated for COST\cite{blogdynamicdatalog, blogvldbsigmod}, with results that
showed a very different picture than the ones depicted by the original article's.

\textbf{Methodology.} To address the aforementioned problem, we conduct a back-to-basics
empirical study of datalog evaluation, revisiting and measuring the core assumptions that go
into the implementation of an evaluator. Straightforward single-threaded, parallel and distributed
implementations of both substitution-based and relational-algebra interpretations are realized alongside common
well-known optimizations. Due to the popularity of the relational approach, we give special focus
to the problem of choosing an indexing data structure, and investigate several alternatives, including
a novel one, to the ubiquitous BTree.

%% Rethink :)
\textbf{Contributions.} In this article we make several contributions to clarifying, benchmarking
and easing pushing the boundaries of datalog evaluation engineering research further by
providing performant and open-source implementations of single-threaded, parallel and distributed evaluators.

\begin{itemize}
	\item \textbf{Techniques and Guidelines.} We study the challenge of building a reasoner from scratch,
	      with no underlying framework, and ponder over all decisions necessary in order to materialize that,
	      alongside with relevant recent literature.
	\item \textbf{New Data Structure.} We introduce the Spine, a simple and clever alternative to the B-Tree that
	      exhibits competitive performance in all benchmarked datalog workloads.
	\item \textbf{Implementation.} All code outputs of this article are coalesced in a rust library named shapiro,
	      consisted of a datalog to relational algebra rewriter, a relational algebra evaluator, and two datalog engines,
	      one that is parallel-capable and supports both substitution-based and relational algebra methods, and other that
	      relies on the state-of-the-art differential dataflow\cite{differential_dataflow} distribution computation framework.
	      The main expected outcome of this library is to provide well-understood-and-reasoned-about baseline implementations
	      from where future research can take advantage of, and reliable COST configurations can be attained.
	\item \textbf{Benchmarking.} We perform two thorough benchmark suites. One evaluates the performance of the developed
	      relational reasoner with multiple different index data structures, and another that compares the performance
	      of the distributed reasoner against four state-of-the-art distributed reasoners. The selected datasets are either
	      from the program analysis, heavy users of not-distributed datalog, or from the semantic web community
	      , which has multiple popular infinitely-scalable benchmarks, and are the main proponents of existential datalog.
\end{itemize}

\section{Related Work}

\textbf{Datalog engines.} There are two kinds of recent relevant datalog engines. The first encompasses
those that push the performance boundary, with the biggest proponents being RDFox\cite{rdfox}, that
proposes the to-date, according to their benchmarks, most scalable parallelisation routine, RecStep\cite{recstep},
that builds on top of a highly efficient relational engine, and DCDatalog\cite{dcdatalog}, that builds upon
an influential query optimizer, DeALS\cite{deals} and extends a work that establishes how some linear
datalog programs could be evaluated in a lock-free manner, to general positive programs.

One of the most high-profile datalog papers of interest has been BigDatalog\cite{bigdatalog}, that
originally used the query optimizer DeALs, and was built on top of the very popular Spark\cite{spark}
distribution framework. Soon after, a prototypical implementation\cite{cog} over Flink\cite{flink},
a distribution framework that supports streaming, Cog, followed. Flink, unlike Spark, supports
iteration, so implementing reasoning did not need to extend the core of the underlying framework. The most
successful attempt at creating a distributed implemention has been Nexus\cite{nexus}, that is also built on Flink,
and makes use of its most advanced feature, incremental stream processing. To date, it is the fastest distributed
implementation.

\textbf{Data structures used in datalog engines.} The core of each datalog engine is consisted of possibly
two main data structures: one to hold the data itself, and another for indexes. Surprisingly little regard is given to
this, compared to algorithms themselves, despite potentially being one of the most detrimental factors for performance
. Binary-decision diagrams\cite{bddbddb}, hash sets\cite{microzee} and B-Trees\cite{souffle_btree} are often used as
either one or both main structures. An important highlight of the importance of data structure implementation is how
in \cite{souffle_btree} Subotic et al, managed to attain an almost 50 times higher performance in certain benchmarks
than other implementations of the same data structure.

\section{Datalog Evaluation}

In this section we review the basics of all concepts related to datalog evaluation, as it is done in the current time.

\subsection{Datalog}

\textit{Datalog}\cite{all_you_ever_wanted_to_ask} is a declarative programming language. A program $P$ is a set of
rules $r$, with each $r$ being a restricted first-order formula of the following form: \[\bigwedge_{i=1}^kB_i(x_1, ..., x_j) \rightarrow \exists (y_1, ..., y_j)H(x_1, ..., x_j, y_1, ..., y_j)\]
with $k$, $j$ as finite integers, $x$ and $y$ as terms, and each $B_i$ and $H$ as predicates. A term can belong
either to the set of variables, or constants, however, it is to be noted that all $y$ are existentially quantified.
The set of all $B_i$ is called the \textit{body}, and $H$ the \textit{head}.

A rule $r$ is said to be datalog, if the set of all $y$ is empty, and no predicate is negated, conversely, a
datalog program is one in which all rules are datalog.
\begin{exmp}{Datalog Program}\label{ex1}
	\[
		P = \left\{  \begin{array}{l}
			\text{SubClassOf}(?x, ?y) \wedge \text{SubClassOf}(?y, ?z) \rightarrow \text{SubClassOf}(?x, ?z) \\
		\end{array}\right\}
	\]
\end{exmp}
Example \ref{ex1} shows a simple valid recursive program. The only rule denotes that \textit{for all x, y, z, if x is
	in a SubClassOf relation with y, and y is in a SubClassOf relation with z, then it follows that x is in a subClassOf
	relation with z}.

The meaning of a datalog program is often\cite{datalog} defined through a \textit{Herbrand Interpretation}. The first step
to attain it is the \textit{Herbrand Universe} $\mathfrak{U}$, the set of all constant, commonly referred to as \textit{ground}, terms.
\begin{exmp}{Herbrand Universe}\label{ex2}
	\[
		S = \left\{ \begin{array}{l}
			\text{SubClassOf}(\text{professor}, \text{employee}) \\
			\text{SubClassOf}(\text{employee}, \text{taxPayer})  \\
			\text{SubClassOf}(\text{employee}, \text{employed})  \\
			\text{SubClassOf}(\text{employed}, \text{employee})
		\end{array}\right\}
	\]
	\[
		\mathfrak{U} = \left\{  \begin{array}{l}
			\text{professor}, \text{employee}, \text{employed}, \text{taxPayer}
		\end{array}\right\}
	\]
\end{exmp}
From the shown universe on example \ref{ex2}, it is possible to build The \textit{Herbrand Base}, the set of all possible truths,
from \textit{facts}, assertions that are true, as represented by the actual constituents of the SubClassOf set.
\begin{exmp}{Herbrand Base}\label{ex3}
	\[
		\mathfrak{B} = S \cup \left\{  \begin{array}{l}
			\text{SubClassOf}(\text{professor}, {professor}) \\
			\text{SubClassOf}(\text{employee}, {employee})   \\
			\text{SubClassOf}(\text{employed}, {employed})   \\
			\text{SubClassOf}(\text{taxPayer}, {taxPayer})   \\
			\text{SubClassOf}(\text{professor}, {taxPayer})  \\
			\text{SubClassOf}(\text{taxPayer}, {professor})  \\
			\text{SubClassOf}(\text{employee}, {professor})  \\
			\text{SubClassOf}(\text{taxPayer}, {employee})
		\end{array}\right\}
	\]
\end{exmp}
On example \ref{ex3}, all facts are indeed \textit{possible}, but not necessarily \textit{derivable} from the actual data and
program. An interpretation $I$ is a subset of $\mathfrak{B}$, and a \textit{model} is an interpretation such that all rules
are satisfied. A rule is satisfied if either the head is true, or if the body is not true.
\begin{exmp}{Models}\label{ex4}
	\[
		I_1 = S \cup \left\{  \begin{array}{l}
			\text{SubClassOf}(\text{professor}, {taxPayer}) \\
			\text{SubClassOf}(\text{employee}, {employee})
		\end{array}\right\}
	\]
	\[
		I_2 = S \cup \left\{  \begin{array}{l}
			\text{SubClassOf}(\text{professor}, {taxPayer}) \\
			\text{SubClassOf}(\text{employee}, {employee})  \\
			\text{SubClassOf}(\text{employed}, {employed})
		\end{array}\right\}
	\]
	\[
		I_3 = S \cup \left\{  \begin{array}{l}
			\text{SubClassOf}(\text{professor}, {taxPayer}) \\
			\text{SubClassOf}(\text{employee}, {employee} ) \\
			\text{SubClassOf}(\text{employed}, {employed})  \\
			\text{SubClassOf}(\text{professor, professor})
		\end{array}\right\}
	\]
\end{exmp}
The first interpretation, $I_1$, from example \ref{ex4}, is not a model, since $\text{SubClassOf}(\text{employed}, \text{employed})$ is satisfied
and present. Despite both $I_2$ and $I_3$ being models, $I_2$ is the \textit{minimal} model, which is the definition of the meaning of the program
over the data. The input data, the database, is named as the \textit{Extensional Database} $EDB$, and the output of the program is the \textit{Intensional Database}
$IDB$.

Let an $DB = EDB \cup IDB$, and for there to be a program $P$. We define the \textit{immediate consequence} of $P$ over $DB$ as all facts
that are either in $DB$, or stem from the result of applying the rules in $P$ to $DB$. The \textit{immediate consequence operator}
$\textbf{I}_C(DB)$ is the union of $DB$ and its immediate consequence, and the $IDB$, at the moment of the application of $\textbf{I}_C(DB)$
is the difference of the union of all previous $DB$ with the $EDB$.


It is trivial to see that $I_C(DB)$ is monotone, and given that both the $EDB$ and $P$ are finite sets, and that $IDB = \emptyset$ at the start,
at some point $I_C(DB) = DB$, since there won't be new facts to be inferred. This point is the \textit{least fixed point} of $I_c(DB)$\cite{datalog},
and happens to be the \textit{minimal} model.
\begin{exmp}{Repeated application of $I_c$}\label{ex5}
	\begin{align*}
		P = \{ Edge(?x, ?y) \rightarrow TC(?x, ?y), TC(?x, ?y), TC(?y, ?z) \rightarrow TC(?x, ?z) \} \\
		EDB = \{ Edge(1, 2), Edge(2, 3), Edge(3, 4) \}                                               \\
		DB = EDB                                                                                     \\
		DB = I_C(DB)                                                                                 \\
		DB == EDB \cup \{ TC(1, 2), TC(2, 3), TC(3, 4) \}                                            \\
		DB = I_C(DB)                                                                                 \\
		DB == EDB \cup \{ TC(1, 2), TC(2, 3), TC(3, 4), TC(1, 3), TC(2, 4) \}                        \\
		DB = I_C(DB)                                                                                 \\
		DB == EDB \cup \{ TC(1, 2), TC(2, 3), TC(3, 4), TC(1, 3), TC(2, 4), TC(1, 4) \}              \\
		DB = I_C(DB)                                                                                 \\
		DB == EDB \cup \{ TC(1, 2), TC(2, 3), TC(3, 4), TC(1, 3), TC(2, 4), TC(1, 4) \}              \\
		IDB = DB \setminus EDB
	\end{align*}
\end{exmp}
The introduced form of evaluation, with a walkthrough given on example \ref{ex5}, is called \textit{naive}, meanwhile, the ubiquitous evaluation
mechanism, as of the date of writing this paper, is the \textit{semi-naive} one. The only difference is that \textit{semi-naive} does not
repeatedly union the $EDB$ with the entire $IDB$, but does so only with the difference of the previous immediate consequence with the $IDB$. This can
be hinted from the example, where each next application of $I_c$ only renders new facts from the previous newly derived ones.

\subsection{Infer}
The most relevant performance-oriented aspect of both of the introduced evaluation mechanisms is the implementation of $I_c$ itself. The two
most high-profile methods to do so are either purely evaluating the rules, or rewriting them in some other imperative formalism, and executing it.

The Infer\cite{datalog} algorithm is the simplest example of the former, and relies on substitutions. A substitution $S$ is a homomorphism
$[x_1 \rightarrow y_1, ..., x_i \rightarrow y_i]$, such that $x_i$ is a variable, and $y_i$ is a constant. Given a not-ground fact,
such as $TC(?x, 4)$, \textit{applying} the substitution $[?x \rightarrow 1]$ to it will yield the ground fact $TC(1, 4)$.

Infer relies on attempting to build and extend substitutions for each fact in each rule body over every single $DB$ fact. Once
all substitutions are made, they are applied to the heads of each rule. Every result of this application that is ground belongs
to the immediate consequence.

\subsection{Relational Algebra}
Relational Algebra\cite{codd_1970} is an imperative language, that explicitly denotes operations over sets of tuples with fixed arity, relations. It is
the most popular database formalism that there is, with virtually every single major database system adhering to the relational model\cite{pg,mysql,sqlserver}
and supporting relational algebra as the SQL compilation target.

Let $R$ and $T$ be relations with arity $r$ and $t$, $\theta$ be a binary operation with a boolean output, $R(i)$ be the i-th column in $R$, and
$R[h, ..., k]$ be the subset of $R$ such that only the columns $h, ..., k$ remain, and Const the set of all constant terms. The following
are the most relevant relational algebra operators and their semantics:
\begin{itemize}
	\item Selection by column $\sigma_{i=j)}(R) = \{ a \in R | a(i) == a(j) \}$
	\item Selection by value $\sigma_{i=k}(R) = \{a \in R | a(i) == k \}$
	\item Projection $\pi_{h, ..., k}(R) = \{(R(i), ..., R(j), \overrightarrow{C}) |  i, j >= 1 \wedge i, j <= r\ \wedge \forall c \in C. c \in \text{Const}$
	\item Product $\times(R, T) = \{(a, b) | a \in R \wedge b \in T \}$
	\item Join $\Join_{i=j} = \{(a, b) | a \in R \wedge b \in T \wedge a(i) == b(j)\}$
\end{itemize}

Rewriting datalog into some form of relational algebra has been the most successful strategy employed by the vast majority of all current state-of-the-art
reasoners\cite{bigdatalog, cog, nexus, recstep, dcdatalog, souffle} mostly due to the extensive industrial and academic research into developing data processing frameworks that
process very large amounts of data, and the techniques that have arisen from these.

In spite of this, there is no open-source library that provides a stand-alone datalog to relational algebra translator, therefore every single
datalog evaluator has to repeat this effort. Moreover, datalog rules translate to a specific form of relational algebra expressions, the
select-project-join $\mathcal{SPJ}$ form.

A relational algebra expression is in the $\mathcal{SPJ}$ form if it consists solely of select, project and join operators. This form
is very often seen in practice, being equivalent to \verb|SELECT ... FROM ... WHERE ...| SQL queries, and highly benefits from being
equivalent to conjunctive queries, that are equivalent to single-rule and non-recursive datalog programs.

We propose a straightforward not-recursive pseudocode algorithm to translate a datalog rule into a $SPJ$ expression tree, in which
relational operators are nodes and leaves are relations. The value proposition of the algorithm is for the resulting tree to be ready
to be recursively executed, alongside having two essential relational optimizations, selection by value pushdown, and melding selection
by column with products into joins, the most important relational operator.
\begin{algorithm} [!h]
	\scriptsize
	\KwIn{A datalog rule $\mathcal{R}$}
	\KwResult{A relational algebra expression $\mathcal{R}_a$}
	\SetKwData{s}{s}
	\BlankLine
	\SetKwProg{Fn}{Function}{ is}{end}
	\SetKwProg{For}{For}{:}{end}

	\Fn{toIncompleteExpression($r$ : Datalog Rule)}{
		let $t$ be a fresh tree

		\For{For every fact $a_i$ in the rule body $b$} {
			create a relation node $r_i$ with the same arity as $a_i$, and its terms representing columns. variable terms
			are column identifiers, and constant terms are temporary-lived proxies for selections.
			\If {$i < len(b) - 1$ } {
				add a product node $p_i$ to $t$.
				set $r_i$ as the left child of $p_i$.
			}\Else {
				\If {$len(b) > 1$} {
					set $r_i$ as the right child of $p_{i - 1}$
				}
			}
			\If {$i > 0$} {
				set $p_i$ as the right child of $p_{i - 1}$
			}
		}
		\textbf{return} $t$
	}
	\Fn{constantToSelection($e$ : Expression)}{
		let $t$ be a copy of $e$

		let $C$ be a map $C : \text{Const} \rightarrow \text{Var}$

		\For {every relation $r_i$ in $t$} {
			\For {every constant $c_j$ in $r_i$}{
				add a selection by value node $s_j$ to $t$ with column index $j$ and value $c_j$

				set $s_j$'s parent to $r_i$'s, and $r_i$ as its left child

				\If {$\neg (c_j \in C)$}{
					create a fresh variable term $v_j$ and store it in $C$ with $c_j$ as the key}
				\Else{replace $c_j$ for the value in $C$ under $c_j$}
			}
		}
		\textbf{return} $t$
	}
	\Fn{equalityToSelection($e$ : Expression)}{
		let $t$ be a copy of $e$

		let $V$ be a map $V : \text{Var} \rightarrow \mathbb{Z}$

		let $t_{p}$ be a pre-order traversal of $t$

		\For {every relation $r_i$ in $t_{p}$} {
			\For {every variable $v_j$ in $r_i$}{
				\If{$\neg (v_j \in V)$}{
					add $v_j$ to $V$ with $j$ as the value
				}\Else{let $k$ be the value of $v_j$ in $V$
					let $p_i$ be the first product to the left of $r_i$ in $t_{p}$

					add a selection by column node $s_j$ to $t$ with left column index $k$ and right column index $j$

					set $s_j$'s parent to $p_i$'s, and $p_i$ as its left child
				}
			}
		}
		\textbf{return} $t$
	}
	\Fn{projectHead($e$ : Expression, $r$ : Datalog Rule)}{
		let $n$ be 0

		let $t$ be a copy of $e$

		let $h$ be the head of $r$

		let $t_{p}$ be a pre-order traversal of $t$

		let $V$ be a map $V : \text{Var} \rightarrow \mathbb{Z}$

		\For {every relation $r_i$ in $t_{p}$}{
			\For {every term $x$ in $r_i$}{
				\If {$x$ is a variable} {
					add $x$ to $V$ with $n$ as value
				}\Else{
					continue
				}
				$n$ += 1

				add projection node $z$ to $t$ and set it as root with an empty list

				\For {every term $x$ in $h$}{
					\If {$x$ is a constant}{
						push $x$ into $z$
					}\Else {
						let $k$ be the value of $x$ in $V$

						push $k$ into $z$
					}
				}
			}
		}

		\textbf{return} $t$
	}
	\Fn{productToJoin($e$ : Expression)}{
		let $t$ be a copy of $e$

		let $t_{p}$ be a pre-order traversal of $t$

		\For {every selection by column $s_i$ in $t_{p}$}{
			find the first product $p_j$ after $s_i$ in $t_{p}$

			remove $s_i$ from $t$, swap $p_j$ for a join $g_j$ in $t$ with left and right column indexes by those of $s_i$
		}
		\textbf{return} t
	}
	$\mathcal{R}_a$ = toIncompleteExpression($\mathcal{R}$)

	$\mathcal{R}_a$ = constantToSelection(expression, $\mathcal{R}$)

	$\mathcal{R}_a$ = equalityToSelection(expression, $\mathcal{R}$)

	$\mathcal{R}_a$ = projectHead(expression, $\mathcal{R}$)

	$\mathcal{R}_a$ = productToJoin(expression, $\mathcal{R}$)

	\textbf{return} $\mathcal{R}_a$
	\caption{An algorithm to translate a datalog rule into relational algebra}
	\label{alg:datalog_to_relalg}
\end{algorithm}

The canonical algorithms for translating datalog to relational algebra\cite{opt_sys_alg_ev_dat}\cite{} are recursive, complex,
and do not assume the output to be an tree, being mostly symbolic.

\section{Shapiro}

\subsection{Single-Threaded and Parallel}

\subsubsection{The Spine}

\subsection{Distributed}

most of the distributed datalog engines are built on top of either graph-processing or map-reduce frameworks
their semantics do not fit datalog like a glove

\subsubsection{Differential Dataflow}

Differential dataflow however, does. It substantially improves semi-naive evaluation by automatically parallelizing it.

Make a graphic example showing how

\section{Experiments}

// No libraries for relational algebra


ACM's consolidated article template, introduced in 2017, provides a
consistent \LaTeX\ style for use across ACM publications, and
incorporates accessibility and metadata-extraction functionality
necessary for future Digital Library endeavors. Numerous ACM and
SIG-specific \LaTeX\ templates have been examined, and their unique
features incorporated into this single new template.

If you are new to publishing with ACM, this document is a valuable
guide to the process of preparing your work for publication. If you
have published with ACM before, this document provides insight and
instruction into more recent changes to the article template.

The ``\verb|acmart|'' document class can be used to prepare articles
for any ACM publication --- conference or journal, and for any stage
of publication, from review to final ``camera-ready'' copy, to the
author's own version, with {\itshape very} few changes to the source.

\section{Template Overview}
As noted in the introduction, the ``\verb|acmart|'' document class can
be used to prepare many different kinds of documentation --- a
double-blind initial submission of a full-length technical paper, a
two-page SIGGRAPH Emerging Technologies abstract, a ``camera-ready''
journal article, a SIGCHI Extended Abstract, and more --- all by
selecting the appropriate {\itshape template style} and {\itshape
		template parameters}.

This document will explain the major features of the document
class. For further information, the {\itshape \LaTeX\ User's Guide} is
available from
\url{https://www.acm.org/publications/proceedings-template}.

\subsection{Template Styles}

The primary parameter given to the ``\verb|acmart|'' document class is
the {\itshape template style} which corresponds to the kind of publication
or SIG publishing the work. This parameter is enclosed in square
brackets and is a part of the {\verb|documentclass|} command:
\begin{verbatim}
  \documentclass[STYLE]{acmart}
\end{verbatim}

Journals use one of three template styles. All but three ACM journals
use the {\verb|acmsmall|} template style:
\begin{itemize}
	\item {\verb|acmsmall|}: The default journal template style.
	\item {\verb|acmlarge|}: Used by JOCCH and TAP.
	\item {\verb|acmtog|}: Used by TOG.
\end{itemize}

The majority of conference proceedings documentation will use the {\verb|acmconf|} template style.
\begin{itemize}
	\item {\verb|acmconf|}: The default proceedings template style.
	      \item{\verb|sigchi|}: Used for SIGCHI conference articles.
	      \item{\verb|sigchi-a|}: Used for SIGCHI ``Extended Abstract'' articles.
	      \item{\verb|sigplan|}: Used for SIGPLAN conference articles.
\end{itemize}

\subsection{Template Parameters}

In addition to specifying the {\itshape template style} to be used in
formatting your work, there are a number of {\itshape template parameters}
which modify some part of the applied template style. A complete list
of these parameters can be found in the {\itshape \LaTeX\ User's Guide.}

Frequently-used parameters, or combinations of parameters, include:
\begin{itemize}
	\item {\verb|anonymous,review|}: Suitable for a ``double-blind''
	      conference submission. Anonymizes the work and includes line
	      numbers. Use with the \verb|\acmSubmissionID| command to print the
	      submission's unique ID on each page of the work.
	      \item{\verb|authorversion|}: Produces a version of the work suitable
	      for posting by the author.
	      \item{\verb|screen|}: Produces colored hyperlinks.
\end{itemize}

This document uses the following string as the first command in the
source file:
\begin{verbatim}
\documentclass[sigconf,authordraft]{acmart}
\end{verbatim}

\section{Modifications}

Modifying the template --- including but not limited to: adjusting
margins, typeface sizes, line spacing, paragraph and list definitions,
and the use of the \verb|\vspace| command to manually adjust the
vertical spacing between elements of your work --- is not allowed.

	{\bfseries Your document will be returned to you for revision if
		modifications are discovered.}

\section{Typefaces}

The ``\verb|acmart|'' document class requires the use of the
``Libertine'' typeface family. Your \TeX\ installation should include
this set of packages. Please do not substitute other typefaces. The
``\verb|lmodern|'' and ``\verb|ltimes|'' packages should not be used,
as they will override the built-in typeface families.

\section{Title Information}

The title of your work should use capital letters appropriately -
\url{https://capitalizemytitle.com/} has useful rules for
capitalization. Use the {\verb|title|} command to define the title of
your work. If your work has a subtitle, define it with the
	{\verb|subtitle|} command.  Do not insert line breaks in your title.

If your title is lengthy, you must define a short version to be used
in the page headers, to prevent overlapping text. The \verb|title|
command has a ``short title'' parameter:
\begin{verbatim}
  \title[short title]{full title}
\end{verbatim}

\section{Authors and Affiliations}

Each author must be defined separately for accurate metadata
identification. Multiple authors may share one affiliation. Authors'
names should not be abbreviated; use full first names wherever
possible. Include authors' e-mail addresses whenever possible.

Grouping authors' names or e-mail addresses, or providing an ``e-mail
alias,'' as shown below, is not acceptable:
\begin{verbatim}
  \author{Brooke Aster, David Mehldau}
  \email{dave,judy,steve@university.edu}
  \email{firstname.lastname@phillips.org}
\end{verbatim}

The \verb|authornote| and \verb|authornotemark| commands allow a note
to apply to multiple authors --- for example, if the first two authors
of an article contributed equally to the work.

If your author list is lengthy, you must define a shortened version of
the list of authors to be used in the page headers, to prevent
overlapping text. The following command should be placed just after
the last \verb|\author{}| definition:
\begin{verbatim}
  \renewcommand{\shortauthors}{McCartney, et al.}
\end{verbatim}
Omitting this command will force the use of a concatenated list of all
of the authors' names, which may result in overlapping text in the
page headers.

The article template's documentation, available at
\url{https://www.acm.org/publications/proceedings-template}, has a
complete explanation of these commands and tips for their effective
use.

Note that authors' addresses are mandatory for journal articles.

\section{Rights Information}

Authors of any work published by ACM will need to complete a rights
form. Depending on the kind of work, and the rights management choice
made by the author, this may be copyright transfer, permission,
license, or an OA (open access) agreement.

Regardless of the rights management choice, the author will receive a
copy of the completed rights form once it has been submitted. This
form contains \LaTeX\ commands that must be copied into the source
document. When the document source is compiled, these commands and
their parameters add formatted text to several areas of the final
document:
\begin{itemize}
	\item the ``ACM Reference Format'' text on the first page.
	\item the ``rights management'' text on the first page.
	\item the conference information in the page header(s).
\end{itemize}

Rights information is unique to the work; if you are preparing several
works for an event, make sure to use the correct set of commands with
each of the works.

The ACM Reference Format text is required for all articles over one
page in length, and is optional for one-page articles (abstracts).

\section{CCS Concepts and User-Defined Keywords}

Two elements of the ``acmart'' document class provide powerful
taxonomic tools for you to help readers find your work in an online
search.

The ACM Computing Classification System ---
\url{https://www.acm.org/publications/class-2012} --- is a set of
classifiers and concepts that describe the computing
discipline. Authors can select entries from this classification
system, via \url{https://dl.acm.org/ccs/ccs.cfm}, and generate the
commands to be included in the \LaTeX\ source.

User-defined keywords are a comma-separated list of words and phrases
of the authors' choosing, providing a more flexible way of describing
the research being presented.

CCS concepts and user-defined keywords are required for for all
articles over two pages in length, and are optional for one- and
two-page articles (or abstracts).

\section{Sectioning Commands}

Your work should use standard \LaTeX\ sectioning commands:
\verb|section|, \verb|subsection|, \verb|subsubsection|, and
\verb|paragraph|. They should be numbered; do not remove the numbering
from the commands.

Simulating a sectioning command by setting the first word or words of
a paragraph in boldface or italicized text is {\bfseries not allowed.}

\section{Tables}

The ``\verb|acmart|'' document class includes the ``\verb|booktabs|''
package --- \url{https://ctan.org/pkg/booktabs} --- for preparing
high-quality tables.

Table captions are placed {\itshape above} the table.

Because tables cannot be split across pages, the best placement for
them is typically the top of the page nearest their initial cite.  To
ensure this proper ``floating'' placement of tables, use the
environment \textbf{table} to enclose the table's contents and the
table caption.  The contents of the table itself must go in the
\textbf{tabular} environment, to be aligned properly in rows and
columns, with the desired horizontal and vertical rules.  Again,
detailed instructions on \textbf{tabular} material are found in the
\textit{\LaTeX\ User's Guide}.

Immediately following this sentence is the point at which
Table~\ref{tab:freq} is included in the input file; compare the
placement of the table here with the table in the printed output of
this document.

\begin{table}
	\caption{Frequency of Special Characters}
	\label{tab:freq}
	\begin{tabular}{ccl}
		\toprule
		Non-English or Math & Frequency   & Comments          \\
		\midrule
		\O                  & 1 in 1,000  & For Swedish names \\
		$\pi$               & 1 in 5      & Common in math    \\
		\$                  & 4 in 5      & Used in business  \\
		$\Psi^2_1$          & 1 in 40,000 & Unexplained usage \\
		\bottomrule
	\end{tabular}
\end{table}

To set a wider table, which takes up the whole width of the page's
live area, use the environment \textbf{table*} to enclose the table's
contents and the table caption.  As with a single-column table, this
wide table will ``float'' to a location deemed more
desirable. Immediately following this sentence is the point at which
Table~\ref{tab:commands} is included in the input file; again, it is
instructive to compare the placement of the table here with the table
in the printed output of this document.

\begin{table*}
	\caption{Some Typical Commands}
	\label{tab:commands}
	\begin{tabular}{ccl}
		\toprule
		Command                    & A Number & Comments         \\
		\midrule
		\texttt{{\char'134}author} & 100      & Author           \\
		\texttt{{\char'134}table}  & 300      & For tables       \\
		\texttt{{\char'134}table*} & 400      & For wider tables \\
		\bottomrule
	\end{tabular}
\end{table*}

Always use midrule to separate table header rows from data rows, and
use it only for this purpose. This enables assistive technologies to
recognise table headers and support their users in navigating tables
more easily.

\section{Math Equations}
You may want to display math equations in three distinct styles:
inline, numbered or non-numbered display.  Each of the three are
discussed in the next sections.

\subsection{Inline (In-text) Equations}
A formula that appears in the running text is called an inline or
in-text formula.  It is produced by the \textbf{math} environment,
which can be invoked with the usual
\texttt{{\char'134}begin\,\ldots{\char'134}end} construction or with
the short form \texttt{\$\,\ldots\$}. You can use any of the symbols
and structures, from $\alpha$ to $\omega$, available in
\LaTeX~\cite{Lamport:LaTeX}; this section will simply show a few
examples of in-text equations in context. Notice how this equation:
\begin{math}
	\lim_{n\rightarrow \infty}x=0
\end{math},
set here in in-line math style, looks slightly different when
set in display style.  (See next section).

\subsection{Display Equations}
A numbered display equation---one set off by vertical space from the
text and centered horizontally---is produced by the \textbf{equation}
environment. An unnumbered display equation is produced by the
\textbf{displaymath} environment.

Again, in either environment, you can use any of the symbols and
structures available in \LaTeX\@; this section will just give a couple
of examples of display equations in context.  First, consider the
equation, shown as an inline equation above:
\begin{equation}
	\lim_{n\rightarrow \infty}x=0
\end{equation}
Notice how it is formatted somewhat differently in
the \textbf{displaymath}
environment.  Now, we'll enter an unnumbered equation:
\begin{displaymath}
	\sum_{i=0}^{\infty} x + 1
\end{displaymath}
and follow it with another numbered equation:
\begin{equation}
	\sum_{i=0}^{\infty}x_i=\int_{0}^{\pi+2} f
\end{equation}
just to demonstrate \LaTeX's able handling of numbering.

\section{Figures}

The ``\verb|figure|'' environment should be used for figures. One or
more images can be placed within a figure. If your figure contains
third-party material, you must clearly identify it as such, as shown
in the example below.
\begin{figure}[h]
	\centering
	\includegraphics[width=\linewidth]{sample-franklin}
	\caption{1907 Franklin Model D roadster. Photograph by Harris \&
		Ewing, Inc. [Public domain], via Wikimedia
		Commons. (\url{https://goo.gl/VLCRBB}).}
	\Description{A woman and a girl in white dresses sit in an open car.}
\end{figure}

Your figures should contain a caption which describes the figure to
the reader.

Figure captions are placed {\itshape below} the figure.

Every figure should also have a figure description unless it is purely
decorative. These descriptions convey what’s in the image to someone
who cannot see it. They are also used by search engine crawlers for
indexing images, and when images cannot be loaded.

A figure description must be unformatted plain text less than 2000
characters long (including spaces).  {\bfseries Figure descriptions
		should not repeat the figure caption – their purpose is to capture
		important information that is not already provided in the caption or
		the main text of the paper.} For figures that convey important and
complex new information, a short text description may not be
adequate. More complex alternative descriptions can be placed in an
appendix and referenced in a short figure description. For example,
provide a data table capturing the information in a bar chart, or a
structured list representing a graph.  For additional information
regarding how best to write figure descriptions and why doing this is
so important, please see
\url{https://www.acm.org/publications/taps/describing-figures/}.

\subsection{The ``Teaser Figure''}

A ``teaser figure'' is an image, or set of images in one figure, that
are placed after all author and affiliation information, and before
the body of the article, spanning the page. If you wish to have such a
figure in your article, place the command immediately before the
\verb|\maketitle| command:
\begin{verbatim}
  \begin{teaserfigure}
    \includegraphics[width=\textwidth]{sampleteaser}
    \caption{figure caption}
    \Description{figure description}
  \end{teaserfigure}
\end{verbatim}

\section{Citations and Bibliographies}

The use of \BibTeX\ for the preparation and formatting of one's
references is strongly recommended. Authors' names should be complete
--- use full first names (``Donald E. Knuth'') not initials
(``D. E. Knuth'') --- and the salient identifying features of a
reference should be included: title, year, volume, number, pages,
article DOI, etc.

The bibliography is included in your source document with these two
commands, placed just before the \verb|\end{document}| command:
\begin{verbatim}
  \bibliographystyle{ACM-Reference-Format}
  \bibliography{bibfile}
\end{verbatim}
where ``\verb|bibfile|'' is the name, without the ``\verb|.bib|''
suffix, of the \BibTeX\ file.

Citations and references are numbered by default. A small number of
ACM publications have citations and references formatted in the
``author year'' style; for these exceptions, please include this
command in the {\bfseries preamble} (before the command
``\verb|\begin{document}|'') of your \LaTeX\ source:
\begin{verbatim}
  \citestyle{acmauthoryear}
\end{verbatim}

Some examples.  A paginated journal article \cite{Abril07}, an
enumerated journal article \cite{Cohen07}, a reference to an entire
issue \cite{JCohen96}, a monograph (whole book) \cite{Kosiur01}, a
monograph/whole book in a series (see 2a in spec. document)
\cite{Harel79}, a divisible-book such as an anthology or compilation
\cite{Editor00} followed by the same example, however we only output
the series if the volume number is given \cite{Editor00a} (so
Editor00a's series should NOT be present since it has no vol. no.),
a chapter in a divisible book \cite{Spector90}, a chapter in a
divisible book in a series \cite{Douglass98}, a multi-volume work as
book \cite{Knuth97}, a couple of articles in a proceedings (of a
conference, symposium, workshop for example) (paginated proceedings
article) \cite{Andler79, Hagerup1993}, a proceedings article with
all possible elements \cite{Smith10}, an example of an enumerated
proceedings article \cite{VanGundy07}, an informally published work
\cite{Harel78}, a couple of preprints \cite{Bornmann2019,
	AnzarootPBM14}, a doctoral dissertation \cite{Clarkson85}, a
master's thesis: \cite{anisi03}, an online document / world wide web
resource \cite{Thornburg01, Ablamowicz07, Poker06}, a video game
(Case 1) \cite{Obama08} and (Case 2) \cite{Novak03} and \cite{Lee05}
and (Case 3) a patent \cite{JoeScientist001}, work accepted for
publication \cite{rous08}, 'YYYYb'-test for prolific author
\cite{SaeediMEJ10} and \cite{SaeediJETC10}. Other cites might
contain 'duplicate' DOI and URLs (some SIAM articles)
\cite{Kirschmer:2010:AEI:1958016.1958018}. Boris / Barbara Beeton:
multi-volume works as books \cite{MR781536} and \cite{MR781537}. A
couple of citations with DOIs:
\cite{2004:ITE:1009386.1010128,Kirschmer:2010:AEI:1958016.1958018}. Online
citations: \cite{TUGInstmem, Thornburg01, CTANacmart}. Artifacts:
\cite{R} and \cite{UMassCitations}.

\section{Acknowledgments}

Identification of funding sources and other support, and thanks to
individuals and groups that assisted in the research and the
preparation of the work should be included in an acknowledgment
section, which is placed just before the reference section in your
document.

This section has a special environment:
\begin{verbatim}
  \begin{acks}
  ...
  \end{acks}
\end{verbatim}
so that the information contained therein can be more easily collected
during the article metadata extraction phase, and to ensure
consistency in the spelling of the section heading.

Authors should not prepare this section as a numbered or unnumbered {\verb|\section|}; please use the ``{\verb|acks|}'' environment.

\section{Appendices}

If your work needs an appendix, add it before the
``\verb|\end{document}|'' command at the conclusion of your source
document.

Start the appendix with the ``\verb|appendix|'' command:
\begin{verbatim}
  \appendix
\end{verbatim}
and note that in the appendix, sections are lettered, not
numbered. This document has two appendices, demonstrating the section
and subsection identification method.

\section{Multi-language papers}

Papers may be written in languages other than English or include
titles, subtitles, keywords and abstracts in different languages (as a
rule, a paper in a language other than English should include an
English title and an English abstract).  Use \verb|language=...| for
every language used in the paper.  The last language indicated is the
main language of the paper.  For example, a French paper with
additional titles and abstracts in English and German may start with
the following command
\begin{verbatim}
\documentclass[sigconf, language=english, language=german,
               language=french]{acmart}
\end{verbatim}

The title, subtitle, keywords and abstract will be typeset in the main
language of the paper.  The commands \verb|\translatedXXX|, \verb|XXX|
begin title, subtitle and keywords, can be used to set these elements
in the other languages.  The environment \verb|translatedabstract| is
used to set the translation of the abstract.  These commands and
environment have a mandatory first argument: the language of the
second argument.  See \verb|sample-sigconf-i13n.tex| file for examples
of their usage.

\section{SIGCHI Extended Abstracts}

The ``\verb|sigchi-a|'' template style (available only in \LaTeX\ and
not in Word) produces a landscape-orientation formatted article, with
a wide left margin. Three environments are available for use with the
``\verb|sigchi-a|'' template style, and produce formatted output in
the margin:
\begin{itemize}
	\item {\verb|sidebar|}:  Place formatted text in the margin.
	\item {\verb|marginfigure|}: Place a figure in the margin.
	\item {\verb|margintable|}: Place a table in the margin.
\end{itemize}

%%
%% The acknowledgments section is defined using the "acks" environment
%% (and NOT an unnumbered section). This ensures the proper
%% identification of the section in the article metadata, and the
%% consistent spelling of the heading.
\begin{acks}
	To Robert, for the bagels and explaining CMYK and color spaces.
\end{acks}

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{sample-base}

%%
%% If your work has an appendix, this is the place to put it.
\appendix

\section{Research Methods}

\subsection{Part One}

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Morbi
malesuada, quam in pulvinar varius, metus nunc fermentum urna, id
sollicitudin purus odio sit amet enim. Aliquam ullamcorper eu ipsum
vel mollis. Curabitur quis dictum nisl. Phasellus vel semper risus, et
lacinia dolor. Integer ultricies commodo sem nec semper.

\subsection{Part Two}

Etiam commodo feugiat nisl pulvinar pellentesque. Etiam auctor sodales
ligula, non varius nibh pulvinar semper. Suspendisse nec lectus non
ipsum convallis congue hendrerit vitae sapien. Donec at laoreet
eros. Vivamus non purus placerat, scelerisque diam eu, cursus
ante. Etiam aliquam tortor auctor efficitur mattis.

\section{Online Resources}

Nam id fermentum dui. Suspendisse sagittis tortor a nulla mollis, in
pulvinar ex pretium. Sed interdum orci quis metus euismod, et sagittis
enim maximus. Vestibulum gravida massa ut felis suscipit
congue. Quisque mattis elit a risus ultrices commodo venenatis eget
dui. Etiam sagittis eleifend elementum.

Nam interdum magna at lectus dignissim, ac dignissim lorem
rhoncus. Maecenas eu arcu ac neque placerat aliquam. Nunc pulvinar
massa et mattis lacinia.

\end{document}
\endinput
%%
%% End of file `sample-authordraft.tex'.
